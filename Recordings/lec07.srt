1
00:00:00,000 --> 00:00:12,000
Alice's password black, it's determined. Well, that means the adversary commits to a certain J, right?

2
00:00:12,000 --> 00:00:21,000
Where J is a P, J, right? Obviously, the adversary knows all the passwords already, right? All N of them, he already knows in the clear.

3
00:00:21,000 --> 00:00:31,000
But which one is really Alice's password? The probability of guessing is 1 over N, correct, guessing correctly.

4
00:00:31,000 --> 00:00:44,000
So, there she goes, there he goes, he says, I'm Alice, here's a password P, J, indeed P, J exists, right?

5
00:00:44,000 --> 00:00:52,000
And P, J will be authenticated correctly by the server, right? So, these are all passwords.

6
00:00:52,000 --> 00:01:02,000
One of them is Alice's, and one of them the adversary will enter. Maybe the same as Alice's, but yeah, with probability 1 over N.

7
00:01:02,000 --> 00:01:09,000
Which one is Alice's password? Can you tell me by looking at this, what could be her password?

8
00:01:09,000 --> 00:01:18,000
This is not a trick question. There's no, there's nothing hiding in there. It's just a set of random cram.

9
00:01:18,000 --> 00:01:29,000
So, but we're not done, right? So, the adversary will likely make a mistake, right? By guessing an incorrect password.

10
00:01:29,000 --> 00:01:41,000
But what now? So, in other words, how do you verify that it's real Alice or an intruder, an attacker?

11
00:01:41,000 --> 00:01:47,000
Well, this is where the cute little thing comes in, and I'll show you in a minute. That's one question, right?

12
00:01:47,000 --> 00:02:00,000
So, how does the system, right? The system verify that this J is from the adversary, this password J is from the adversary, but password I is from Alice?

13
00:02:00,000 --> 00:02:10,000
And the second, how do we generate these hiding words? So, they all look like what you saw earlier, kind of like indistinguishable or equally likely to be a password.

14
00:02:10,000 --> 00:02:30,000
And you can see that if you generate random passwords that sound like, that look like no human could remember them, and one of the passwords for Alice is something predictable like my friend Bob, then clearly that is the password.

15
00:02:30,000 --> 00:02:41,000
So, that's a tricky question, right? How do we make the bogus passwords, the decoys look real? And then there's, okay, how do you respond?

16
00:02:41,000 --> 00:02:53,000
So, the idea is very simple. You have the system that has, I mean, I'm just showing this as a, the system that has the password, the fc password file.

17
00:02:53,000 --> 00:03:04,000
And it has basically all this, it has means of verifying all these passwords. But in addition to the system that exists today, okay, this is what we already have today.

18
00:03:04,000 --> 00:03:14,000
But instead, I mean, in addition to that, we also introduced a new component, physically separate component, called the honey checker.

19
00:03:14,000 --> 00:03:24,000
And a honey checker's only task is to remember, for every user, the index. The honey checker knows no passwords.

20
00:03:24,000 --> 00:03:34,000
So, think of it as like a really, like, brain damage component, like really stupid component. It just does one thing.

21
00:03:34,000 --> 00:03:55,000
It gets a user name and an index. And it says, yes or no. Yeah? That's it. That's pretty much 99% of it.

22
00:03:55,000 --> 00:04:06,000
So, when Alice logs in, right, and supplies password i, the system will check the password i as it already does today.

23
00:04:06,000 --> 00:04:17,000
Nothing changes so far. But in addition, once they check fast, right, once the password i has been authenticated as Alice's password,

24
00:04:17,000 --> 00:04:27,000
the index i is sent over to the honey checker. And the honey checker does a quick lookup in its little database and says,

25
00:04:27,000 --> 00:04:42,000
Alice has index 5. Is i 5? Yes. All good. Nothing happens. But if i is anything other than 5, well.

26
00:04:42,000 --> 00:04:53,000
So, Alice applies the password. The password is matched to pi, right?

27
00:04:53,000 --> 00:05:02,000
You're so far with me, right? It's not exactly that easy because actually the honey checker needs to compute,

28
00:05:02,000 --> 00:05:09,000
remember, this assaulted hash? But he doesn't know what the i is, right?

29
00:05:09,000 --> 00:05:16,000
So, remember, over here, over here, the password, I show them as being here, but they're not stored like this, right?

30
00:05:16,000 --> 00:05:21,000
Do you remember how they are stored? They are stored in the hash, salted hash form.

31
00:05:21,000 --> 00:05:30,000
So, when Alice supplies the p, the system needs to look up all the Alice's, all the m-t-gerts-part into Alice's,

32
00:05:30,000 --> 00:05:41,000
on each one, compute the salted hash, right? Because the salts are different. So, she computes the salted hash,

33
00:05:41,000 --> 00:05:53,000
then she says, oh, there is a match to pi. And then it sends i over to the honey checker.

34
00:05:53,000 --> 00:06:02,000
And the honey checker just says, yes, does nothing. Or, if the adversary or somebody supplies,

35
00:06:02,000 --> 00:06:11,000
well, it has to be the adversary, actually, if they combine it, be j. And the j, and at this point, the system does not know.

36
00:06:11,000 --> 00:06:18,000
Notice, this big box here, this system has no idea what the index for Alice is, what the index for Bob is.

37
00:06:18,000 --> 00:06:25,000
It does not know any indices. It just knows it has m entries for every user.

38
00:06:25,000 --> 00:06:34,000
So, all it does, it authenticates the user using the supplied password. If authentication succeeds, it says, oh, this corresponds to j,

39
00:06:34,000 --> 00:06:51,000
j, and it sends j to the honey checker. Bam. Wrong. Aligned. So, now you see the whole thing.

40
00:06:51,000 --> 00:06:58,000
Most of the time, the honey checker does absolutely nothing other than just do a lookup. If a lookup succeeds, all good.

41
00:06:58,000 --> 00:07:09,000
That means that j matches i. But if a j is not i, alarm. What does it actually mean?

42
00:07:09,000 --> 00:07:19,000
Notice, if somebody is trying to guess Alice's password, if the adversary does not have the password file,

43
00:07:19,000 --> 00:07:27,000
but it's trying to guess Alice's password. With high probability, with all-knowing probability,

44
00:07:27,000 --> 00:07:35,000
the password that the adversary guesses will not hash into any of Alice's honey passwords, right?

45
00:07:35,000 --> 00:07:47,000
There's only an N of them. So, that's life as usual. The system will say, wrong password, as it does today, right?

46
00:07:47,000 --> 00:07:58,000
And you'll say, just wrong password. Invalid, invalid username, password combination. Yeah? Okay.

47
00:07:58,000 --> 00:08:02,000
So, that experience doesn't change. Alice mistypes her own password.

48
00:08:02,000 --> 00:08:10,000
Forget to shift, cap, whatever. No problem. Wrong username, password combination. Try again.

49
00:08:10,000 --> 00:08:26,000
Same as you do today. But the only way, the only way, again, with high probability, the only way that somebody will guess, or have in their possession,

50
00:08:26,000 --> 00:08:39,000
Alice's password, which is not hers, right? Which is one of the, not i's, right? Anything but i, is going to be somebody who cracked the password file.

51
00:08:39,000 --> 00:08:45,000
Does that make sense? That's the cause for alarm.

52
00:08:45,000 --> 00:08:52,000
So, you wouldn't want any of these alternate passwords to be a very commonly known password?

53
00:08:52,000 --> 00:09:04,000
Right. Right. You don't want them because then you'll be confused, right? Is it, because it has, it cannot be something that somebody would guess about Alice, like trivially, right?

54
00:09:04,000 --> 00:09:13,000
So, that's the, that goes back to how do you generate these details, right? The other question. How do you generate? We are not there yet.

55
00:09:13,000 --> 00:09:21,000
So far, so good? So, yeah, this is already what I mentioned. If the true password is submitted, the user is authenticated.

56
00:09:21,000 --> 00:09:30,000
If a password that is not in the set of Alice's password is submitted, that's a normal authentication error. Okay?

57
00:09:30,000 --> 00:09:39,000
If, if a non Alice's, if a password is submitted, that is one of Alice's, but is indexed, not i, then an alarm is raised.

58
00:09:39,000 --> 00:09:46,000
Only a breach, right? Can cause this. Now you should be convinced. And as you said, they have to be non-treated.

59
00:09:46,000 --> 00:09:59,000
So, if you choose the honey words, judiciously, they will not be like a, a coincidence, right? That you, that somebody, without breaking the password file,

60
00:09:59,000 --> 00:10:09,000
typed in one of the honey passwords. But interestingly enough, as far as Alice, Bob, Charlie, any user is concerned,

61
00:10:09,000 --> 00:10:14,000
there is no change in their experience, right? They don't need to remember two passwords. They still remember one.

62
00:10:14,000 --> 00:10:20,000
They still enter user name, password, hit return. Nothing changes. That's another nice thing.

63
00:10:20,000 --> 00:10:29,000
You don't want to change the user experience, right? Because user experience requires change, requires training. Adaption. Right?

64
00:10:29,000 --> 00:10:35,000
Different users adapt differently. But if you tell them, oh, it's the same as before, just there is something in the back.

65
00:10:35,000 --> 00:10:41,000
Maybe you don't even tell them. They don't need to know.

66
00:10:41,000 --> 00:10:55,000
So, the nice feature here is that the system that today hosts the password file that authenticates you, just needs to transmit the index.

67
00:10:55,000 --> 00:11:02,000
Like minimal information, right? Just name of the person, of the user, and the index.

68
00:11:02,000 --> 00:11:13,000
And so, very little modification, right? You just introduce kind of a call, right? An additional call after you have authenticated the password, right?

69
00:11:13,000 --> 00:11:20,000
Here. After the password has authenticated, you take the index, and the user name, and send it to the honey checker.

70
00:11:20,000 --> 00:11:31,000
And you wait for reply, right? And if the honey checker says yes, cool, honey checker says no, alarm, lock up everything, yeah.

71
00:11:31,000 --> 00:11:40,000
And this is kind of a very trivial way of implementing distributed security, right?

72
00:11:40,000 --> 00:11:44,000
So, the honey checker, of course, is not a full-blown computer system with accounts, right?

73
00:11:44,000 --> 00:11:52,000
You want the honey checker to be a device or a computer that is at most as one account, I mean, basically, like, administering,

74
00:11:52,000 --> 00:12:00,000
user, right? Or a root account that is touched and logged in almost never, right?

75
00:12:00,000 --> 00:12:06,000
Only when the password file and indices are updated.

76
00:12:06,000 --> 00:12:17,000
In fact, you can keep indices the same even if you change the passwords, because they are only known to the honey checker.

77
00:12:17,000 --> 00:12:26,000
No single point of compromise. So, for example, if the computer system is compromised, well, we said, right,

78
00:12:26,000 --> 00:12:34,000
the password file is a hack, you learn about it, right? Because the first user, the first time the adversary

79
00:12:34,000 --> 00:12:40,000
threshold again for any user, for any Alice, Bob, and Charlie, alarm will be erased, and that's it.

80
00:12:40,000 --> 00:12:47,000
The adversary gets one chance. And so, whatever user he picks, Bob, Charlie, Alice, assuming, let's say,

81
00:12:47,000 --> 00:12:54,000
n is some reasonable number, like 20, his chances of getting in a one out of 20.

82
00:12:54,000 --> 00:13:01,000
He might get like, but he's got only one chance, and it's one out of 20.

83
00:13:01,000 --> 00:13:06,000
How long would you update the password without knowing you being fixed?

84
00:13:06,000 --> 00:13:15,000
Well, that has to be done offline. That's not the pretty part. Because if you want to update, if you, well, let's think about it.

85
00:13:15,000 --> 00:13:17,000
You can do it if they gave you their old password.

86
00:13:17,000 --> 00:13:23,000
Yeah, yeah, yeah. I mean, password change, password change programs are separate. Actually, that's a whole, like, separate lecture.

87
00:13:23,000 --> 00:13:38,000
Doing password changes is an underappreciated problem, and a difficult one. Especially considering what happens if you have disconnects in the process.

88
00:13:38,000 --> 00:13:47,000
Meaning that, at some point, the protocol for changing password breaks, like because of the system malfunction or network disconnect,

89
00:13:47,000 --> 00:13:53,000
and you have essentially a user who thinks the password changed, the system does not, or the other way around.

90
00:13:53,000 --> 00:13:57,000
So, that's a careful thing. That's a problem with all password changes, right?

91
00:13:57,000 --> 00:14:03,000
So, the only way to assure your password changes is to actually manually log in into the system and password change,

92
00:14:03,000 --> 00:14:09,000
instead of remotely, physically close. All right? But, that's not scalable, right? We don't want to do that.

93
00:14:09,000 --> 00:14:16,000
So, that's a whole different headache that is not really different, so much different from the, the case when you use Honey,

94
00:14:16,000 --> 00:14:29,000
Honey passwords. But, let's see. If the Honey checker fails, right? It just, the system still will function, right?

95
00:14:29,000 --> 00:14:36,000
Like, if Honey checker goes down, it uses a hardware failure, or some sort, or it gets disconnected,

96
00:14:36,000 --> 00:14:43,000
the system will function. It will just default to what we have today. It will get no worse than what we have today.

97
00:14:43,000 --> 00:14:50,000
So, if the computer system fails, well, you can't log in, but that's the same experience we have today, right?

98
00:14:50,000 --> 00:14:58,000
So, nothing changes so much, if either component, right, is compromised, you don't, it's not failed.

99
00:14:58,000 --> 00:15:08,000
If you, well, sorry, if it fails, if it fails, it's not failed. Now, if either is compromised, like I said, if the computer system is compromised,

100
00:15:08,000 --> 00:15:15,000
well, that's the case we already assumed, right? That the adversary compromised it, and learned the password.

101
00:15:15,000 --> 00:15:22,000
Now, if somebody compromised the Honey checker, without compromising the system, right? So, okay, this is secure,

102
00:15:22,000 --> 00:15:30,000
the adversary does not know the et cetera password file. It just breaks in here, oh, the adversary learns usernames and indices,

103
00:15:30,000 --> 00:15:40,000
but that's it. That doesn't help the adversary to log in. Now, what happens if the adversary compromises both, which is, of course, should be unlikely.

104
00:15:40,000 --> 00:15:45,000
If the adversary compromises both, it gets no worse than we already have.

105
00:15:45,000 --> 00:15:50,000
If you think it through, the situation is strictly no worse than we have today.

106
00:15:50,000 --> 00:15:55,000
Because when the adversary learned the indices, and the adversary learned the password file,

107
00:15:55,000 --> 00:16:01,000
well, he just still has to brute force all the passwords, right, as he would today, so nothing changes.

108
00:16:01,000 --> 00:16:14,000
And Honey checker can be a very, very, like a simple operation.

109
00:16:14,000 --> 00:16:24,000
This may not be, so, if you have, for example, a wire between them, right, like an ethernet wire or some other fiber optic wire

110
00:16:24,000 --> 00:16:35,000
between the computer system and the Honey checker, basically you don't even need any output from the Honey checker.

111
00:16:35,000 --> 00:16:44,000
And the reason is that you know that it received, right? When you send something over a wire, you know it will be received.

112
00:16:44,000 --> 00:16:49,000
Then you have a dedicated wire between the two devices.

113
00:16:49,000 --> 00:16:54,000
So, what if nothing, what if, what if this is a legitimate login?

114
00:16:54,000 --> 00:16:58,000
Well, silence, everything okay?

115
00:16:58,000 --> 00:17:03,000
What if it's illegitimate, meaning that this is an adversary supplying some BJ?

116
00:17:03,000 --> 00:17:06,000
Well, in that case, a physical alarm will go on, right?

117
00:17:06,000 --> 00:17:09,000
The doors will lock, the administrator will be alerted, right?

118
00:17:09,000 --> 00:17:14,000
So, some physical consequences will happen, right?

119
00:17:14,000 --> 00:17:23,000
So, what this is, essentially, it's an input-only system, that you just give it name, index, name, index.

120
00:17:23,000 --> 00:17:27,000
And in case of a problem, it will raise a real alarm.

121
00:17:27,000 --> 00:17:33,000
In practice, you may still want to know as soon as possible, but still.

122
00:17:33,000 --> 00:17:35,000
Make sense?

123
00:17:35,000 --> 00:17:42,000
So, it can be, like, downstream somewhere in an operations center.

124
00:17:42,000 --> 00:17:53,000
So, clearly, you want the Honey checker to be more secure, because this is obviously accessed by, this system will have multiple user accounts, right?

125
00:17:53,000 --> 00:17:55,000
Because they are all logging into it.

126
00:17:55,000 --> 00:17:57,000
They will have the system administrator.

127
00:17:57,000 --> 00:18:00,000
The Honey checker can be, basically, not untouched, for the most part.

128
00:18:00,000 --> 00:18:12,000
So, sitting there, in a box somewhere, does it need a screen, does it need anything, just sit in a box, in a closet, in a, you know, behind an armored door or something, and that's it.

129
00:18:12,000 --> 00:18:13,000
Right?

130
00:18:13,000 --> 00:18:15,000
It just gives this sort of rapid alert.

131
00:18:15,000 --> 00:18:16,000
Right?

132
00:18:16,000 --> 00:18:17,000
So, I reset that.

133
00:18:17,000 --> 00:18:18,000
Okay.

134
00:18:18,000 --> 00:18:22,000
Now, we come back to this issue of Honey word generation.

135
00:18:22,000 --> 00:18:23,000
How do you do it?

136
00:18:23,000 --> 00:18:25,000
Now, look at this.

137
00:18:25,000 --> 00:18:27,000
Which one is the password?

138
00:18:27,000 --> 00:18:36,000
Obviously, the next to last, because it's the only one that looks like human language.

139
00:18:36,000 --> 00:18:39,000
The rest look pretty random.

140
00:18:39,000 --> 00:18:48,000
So, it's very likely, I'm not guaranteed, maybe Alice is a genius, can remember, like one of those savants, can remember a string of two characters, but don't like it.

141
00:18:48,000 --> 00:18:49,000
Right?

142
00:18:49,000 --> 00:18:50,000
So, boom.

143
00:18:50,000 --> 00:18:51,000
Done.

144
00:18:51,000 --> 00:18:52,000
This one.

145
00:18:52,000 --> 00:18:56,000
So, well, what could we do?

146
00:18:56,000 --> 00:19:08,000
Remember, we have Password Crackers, the software, right, that, that, you know, breaks passwords, and it, you know, generates human readable passwords.

147
00:19:08,000 --> 00:19:21,000
So, we can kind of take passwords, right, potentially decoy passwords, from prior breaches of, like, of password databases, and repurpose them.

148
00:19:21,000 --> 00:19:30,000
By adding a letter, a number here, an exclamation, or a question mark, or a comma, or a period, right?

149
00:19:30,000 --> 00:19:34,000
Because they are already human passwords, right?

150
00:19:34,000 --> 00:19:36,000
The ones from, like, a raw human database.

151
00:19:36,000 --> 00:19:49,000
Just grab some, not too popular, but, like, grab some mildly popular password, and tweak it a little bit, and make it a decoy.

152
00:19:49,000 --> 00:19:50,000
Right?

153
00:19:50,000 --> 00:19:55,000
So, let's say it's something like this.

154
00:19:55,000 --> 00:20:00,000
Well, now, now it's difficult, right?

155
00:20:00,000 --> 00:20:06,000
If you're that attacker, you're, you're kind of out of luck, looking at these, these passwords.

156
00:20:06,000 --> 00:20:13,000
They could all be Alice's password.

157
00:20:13,000 --> 00:20:18,000
Happens to be that, but could have been any other?

158
00:20:18,000 --> 00:20:21,000
Okay, there are problem cases.

159
00:20:21,000 --> 00:20:34,000
Now, if you look at this, which would be more likely to be the password here?

160
00:20:34,000 --> 00:20:36,000
My guess is, not wild guess, right?

161
00:20:36,000 --> 00:20:38,000
It's probably the second, right?

162
00:20:38,000 --> 00:20:41,000
It just kind of sticks out at you.

163
00:20:41,000 --> 00:20:42,000
Right?

164
00:20:42,000 --> 00:20:45,000
It's mostly more timely, also.

165
00:20:45,000 --> 00:20:46,000
All right.

166
00:20:46,000 --> 00:20:49,000
So, not good, right?

167
00:20:49,000 --> 00:20:51,000
This is not a good selection.

168
00:20:51,000 --> 00:21:03,000
Now, if every one of them said, I don't know, down with Joe Biden, down with Donald Trump, down with Gavin Newsom, down with, I don't know, Maduro, et cetera.

169
00:21:03,000 --> 00:21:04,000
Yes.

170
00:21:04,000 --> 00:21:05,000
Okay.

171
00:21:05,000 --> 00:21:08,000
That would be hot.

172
00:21:08,000 --> 00:21:10,000
Because they all look very similar.

173
00:21:10,000 --> 00:21:13,000
But, but this, hmm.

174
00:21:13,000 --> 00:21:24,000
So, one way to generate similar believable passwords is by what's called tweaking.

175
00:21:24,000 --> 00:21:25,000
Oh, yeah.

176
00:21:25,000 --> 00:21:33,000
So, essentially, you know, I'll put you to the paper, but of course nobody's going to look at it, but the idea is very similar.

177
00:21:33,000 --> 00:21:35,000
Tweak the actual password.

178
00:21:35,000 --> 00:21:48,000
Take, take the user's actual password that he or she picked and tweak them a little bit to generate, like, minor variations.

179
00:21:48,000 --> 00:21:58,000
That has problems, but, something like this.

180
00:21:58,000 --> 00:22:05,000
So, both lines are passwords, like gamma half, pacificer six, and this is contamination, right?

181
00:22:05,000 --> 00:22:08,000
So, all four of these are passwords.

182
00:22:08,000 --> 00:22:16,000
I mean, nobody, I'm saying, well, he thinks that your password is very long, but, but you get the idea, right?

183
00:22:16,000 --> 00:22:18,000
They all have similar structure.

184
00:22:18,000 --> 00:22:24,000
They all start with, like, the same sort of human readable part, and then there are these numbers, right?

185
00:22:24,000 --> 00:22:30,000
Three, two, one, four, five, six, seven, and then there are the sequential numbers, but they all look very similar.

186
00:22:30,000 --> 00:22:34,000
Now, looking at this, it's very hard to say, right?

187
00:22:34,000 --> 00:22:42,000
So, one of them is, is obviously the password, and the rest are tweaked, but which are tweaked?

188
00:22:42,000 --> 00:22:43,000
Why?

189
00:22:43,000 --> 00:22:49,000
Because all the other ones, it has the one that has the most common numbers and letters.

190
00:22:49,000 --> 00:22:56,000
Maybe, maybe, maybe, but it happens to be this one.

191
00:22:56,000 --> 00:23:01,000
No, I mean that, of course, it's a synthetic example, but it happens to be this one.

192
00:23:01,000 --> 00:23:08,000
But you get the idea, chaffing is a, does everybody know what the word chaff means?

193
00:23:08,000 --> 00:23:17,000
Chaffing, like, when you have weak chaff, you know, stuff that is like fluff, noise.

194
00:23:17,000 --> 00:23:22,000
So, the rest of them are noise, right?

195
00:23:22,000 --> 00:23:26,000
So, here's another problem.

196
00:23:26,000 --> 00:23:33,000
Here you have a bunch of very similar passwords, right?

197
00:23:33,000 --> 00:23:38,000
Which one is the real password?

198
00:23:38,000 --> 00:23:40,000
Any guesses?

199
00:23:40,000 --> 00:23:45,000
I know you, you have a guess, but does anybody want to guess?

200
00:23:45,000 --> 00:23:46,000
Okay.

201
00:23:46,000 --> 00:23:47,000
It's the fourth one.

202
00:23:47,000 --> 00:23:48,000
It's the fourth one.

203
00:23:48,000 --> 00:23:49,000
Why?

204
00:23:49,000 --> 00:23:50,000
The band.

205
00:23:50,000 --> 00:23:51,000
The band.

206
00:23:51,000 --> 00:23:55,000
Now, of course, now you know this, except for him, I don't know why he knows, but it's

207
00:23:55,000 --> 00:24:00,000
a band from, you know, some, a couple of generations before you.

208
00:24:00,000 --> 00:24:01,000
It's a rock band, right?

209
00:24:01,000 --> 00:24:06,000
So, it has meaning.

210
00:24:06,000 --> 00:24:09,000
The rest of them are kind of random, right?

211
00:24:09,000 --> 00:24:11,000
But this one has a real meaning.

212
00:24:11,000 --> 00:24:17,000
Looks random, but it is not.

213
00:24:17,000 --> 00:24:25,000
So, the semantics of these particular passwords are significant, whereas the rest of them don't

214
00:24:25,000 --> 00:24:27,000
have any real semantics.

215
00:24:27,000 --> 00:24:32,000
So, if you just tweak by generation, like if the real password is Blink 182, and you start

216
00:24:32,000 --> 00:24:38,000
generating Blink 123, Blink 183, well, none of them are rock band.

217
00:24:38,000 --> 00:24:42,000
So, somebody who knows this will look at it and say, uh-huh, I know exactly what the password

218
00:24:42,000 --> 00:24:43,000
is.

219
00:24:43,000 --> 00:24:45,000
That's difficult.

220
00:24:45,000 --> 00:24:50,000
I think today you can get GBT to generate some meaningful passwords.

221
00:24:50,000 --> 00:24:55,000
Maybe, now this stuff wasn't proposed in an LLM era, right?

222
00:24:55,000 --> 00:24:56,000
It was before.

223
00:24:56,000 --> 00:24:57,000
Yeah.

224
00:24:57,000 --> 00:24:58,000
You probably can.

225
00:24:58,000 --> 00:24:59,000
But there's a better idea.

226
00:24:59,000 --> 00:25:05,000
You can just repurpose other people's passwords.

227
00:25:05,000 --> 00:25:11,000
You know, even conceivably on the same system takes Bob's and Charlie's passwords and throw

228
00:25:11,000 --> 00:25:14,000
them in his chaff and Alice's mix.

229
00:25:14,000 --> 00:25:18,000
They're as believable as Alice's passwords, you see?

230
00:25:18,000 --> 00:25:21,000
You can do that.

231
00:25:21,000 --> 00:25:24,000
Well, basically, what is this?

232
00:25:24,000 --> 00:25:25,000
What is the idea?

233
00:25:25,000 --> 00:25:27,000
What is the honey password scheme?

234
00:25:27,000 --> 00:25:34,000
It's an example of distributed security, kind of inexpensive distributed security that

235
00:25:34,000 --> 00:25:38,000
strictly strengthens the resilience of the system.

236
00:25:38,000 --> 00:25:40,000
Now, it's not going to prevent password breaches.

237
00:25:40,000 --> 00:25:43,000
It has absolutely nothing to do with prevention.

238
00:25:43,000 --> 00:25:48,000
It has everything to do with timely detection.

239
00:25:48,000 --> 00:25:49,000
Okay?

240
00:25:49,000 --> 00:25:57,000
So, it will, it's purpose only one, to detect ASAP when something happens, like a password

241
00:25:57,000 --> 00:26:00,000
file is compromised and the adversary tries to gain access.

242
00:26:00,000 --> 00:26:01,000
Yeah?

243
00:26:01,000 --> 00:26:06,000
Can the adversary use these correct passwords and maybe attempt them on a different website?

244
00:26:06,000 --> 00:26:07,000
Of course!

245
00:26:07,000 --> 00:26:09,000
And they're forgetting that they're using the password.

246
00:26:09,000 --> 00:26:10,000
Of course.

247
00:26:10,000 --> 00:26:11,000
Of course.

248
00:26:11,000 --> 00:26:12,000
This is not a panacea.

249
00:26:12,000 --> 00:26:14,000
This is not magic, right?

250
00:26:14,000 --> 00:26:17,000
The adversary stole the password file.

251
00:26:17,000 --> 00:26:20,000
And Greg told his password.

252
00:26:20,000 --> 00:26:25,000
He can try them on a different system because many of us, we use passwords.

253
00:26:25,000 --> 00:26:28,000
We do, unfortunately.

254
00:26:28,000 --> 00:26:36,000
Now, some, some password guideline checkers, you know how when you select your password,

255
00:26:36,000 --> 00:26:42,000
you are asked to enter, I mean, must have at least one lowercase, one uppercase, one special character,

256
00:26:42,000 --> 00:26:43,000
and one number, right?

257
00:26:43,000 --> 00:26:45,000
I think usually that's what you see I say.

258
00:26:45,000 --> 00:26:46,000
And the length, right?

259
00:26:46,000 --> 00:26:49,000
Eight characters at least, I think, for us.

260
00:26:49,000 --> 00:26:53,000
What was the last time anybody changed the password?

261
00:26:53,000 --> 00:26:56,000
I think I have.

262
00:26:56,000 --> 00:26:57,000
Okay.

263
00:26:57,000 --> 00:26:59,000
You haven't changed the password either.

264
00:26:59,000 --> 00:27:00,000
I have.

265
00:27:00,000 --> 00:27:01,000
I have.

266
00:27:01,000 --> 00:27:02,000
But I just don't remember the number.

267
00:27:02,000 --> 00:27:07,000
There are these other rules, but I remember, I think it, I think it's eight.

268
00:27:07,000 --> 00:27:15,000
Anyway, so some of the systems will have an additional guideline where you must insert

269
00:27:15,000 --> 00:27:20,000
the name of the system you are logging in into your password.

270
00:27:20,000 --> 00:27:23,000
Meaning that this is like uci.edu.

271
00:27:23,000 --> 00:27:27,000
So your password should have uci.edu in it.

272
00:27:27,000 --> 00:27:28,000
That is a pain.

273
00:27:28,000 --> 00:27:33,000
Not because if you have uci.edu, that part isn't useful.

274
00:27:33,000 --> 00:27:38,000
So you have to essentially add this to your password at the end or in the beginning.

275
00:27:38,000 --> 00:27:40,000
You're not going to sprinkle it throughout.

276
00:27:40,000 --> 00:27:46,000
And if the limit is eight, well you should not count these seven characters as part of

277
00:27:46,000 --> 00:27:47,000
the password.

278
00:27:47,000 --> 00:27:49,000
And for strength purposes, right?

279
00:27:49,000 --> 00:27:54,000
So essentially, by mandating that you all use uci.edu in your password, I'm saying that

280
00:27:54,000 --> 00:28:00,000
your password has to be at least 15 characters long, right?

281
00:28:00,000 --> 00:28:03,000
You see what I'm saying?

282
00:28:03,000 --> 00:28:06,000
Now, but that would solve a problem, right?

283
00:28:06,000 --> 00:28:12,000
In that you could not then reuse, well, it would be awkward for you to reuse that same

284
00:28:12,000 --> 00:28:21,000
password because it contains uci.edu on, I don't know, wellsfarga.com.

285
00:28:21,000 --> 00:28:26,000
But that's a balance between password usability and password strength.

286
00:28:26,000 --> 00:28:28,000
Now, back to your question.

287
00:28:28,000 --> 00:28:29,000
There's one other problem.

288
00:28:29,000 --> 00:28:32,000
Yes, the adversary could try.

289
00:28:32,000 --> 00:28:37,000
But remember, the adversary still doesn't know the right index.

290
00:28:37,000 --> 00:28:42,000
So it's very likely it's going to be frustrating for the adversary if the other system also

291
00:28:42,000 --> 00:28:44,000
implements a honey checker.

292
00:28:44,000 --> 00:28:46,000
Well, they would have different honey.

293
00:28:46,000 --> 00:28:47,000
That's right.

294
00:28:47,000 --> 00:28:50,000
But then they usually have different passwords.

295
00:28:50,000 --> 00:28:55,000
Right, but they just have to try like 20 times and then one of them works.

296
00:28:55,000 --> 00:28:56,000
No, no, no.

297
00:28:56,000 --> 00:29:02,000
Yes, if the other system, so let's say you broke into, you got uci.edu password for you.

298
00:29:02,000 --> 00:29:07,000
And then you went to Wells Fargo and they tried to log in as u using those passwords.

299
00:29:07,000 --> 00:29:12,000
But if Wells Fargo also implements a honey checker, that ain't going to work, right?

300
00:29:12,000 --> 00:29:15,000
I mean, it ain't going to work.

301
00:29:15,000 --> 00:29:17,000
Actually, no, let me take it back.

302
00:29:17,000 --> 00:29:24,000
It will work because one of them is probably, yeah, not probably, one of them is going to overlap.

303
00:29:24,000 --> 00:29:27,000
So actually, yeah, it might actually work.

304
00:29:27,000 --> 00:29:28,000
You need to compare it.

305
00:29:28,000 --> 00:29:29,000
That's right.

306
00:29:29,000 --> 00:29:31,000
Well, no, no, you don't have to break in to compare.

307
00:29:31,000 --> 00:29:33,000
If you break into Wells Fargo, then you can compare.

308
00:29:33,000 --> 00:29:34,000
But that's a high bar.

309
00:29:34,000 --> 00:29:36,000
I think actually you're right.

310
00:29:36,000 --> 00:29:39,000
You could take them to another website and try 20 times.

311
00:29:39,000 --> 00:29:42,000
Now, after three or four times, you'll get locked out.

312
00:29:42,000 --> 00:29:45,000
So you would have to do this under radar.

313
00:29:45,000 --> 00:29:55,000
Remember I mentioned that a good hacker or adversary does not rush to victory.

314
00:29:55,000 --> 00:30:04,000
If I know 10 passwords for you and only one is real, I'm not going to try one after another.

315
00:30:04,000 --> 00:30:08,000
I'm going to try one and cross it off by myself.

316
00:30:08,000 --> 00:30:10,000
And I'm going to get an education payment.

317
00:30:10,000 --> 00:30:20,000
Then knowing that you log into Wells Fargo once a day, suppose, I will wait a day.

318
00:30:20,000 --> 00:30:24,000
And during that time, you would have logged in successfully.

319
00:30:24,000 --> 00:30:25,000
Okay?

320
00:30:25,000 --> 00:30:26,000
Reset the counter.

321
00:30:26,000 --> 00:30:29,000
I will try the second answer.

322
00:30:29,000 --> 00:30:30,000
Doesn't work?

323
00:30:30,000 --> 00:30:31,000
Cross that off.

324
00:30:31,000 --> 00:30:32,000
Wait another day.

325
00:30:32,000 --> 00:30:34,000
You get what I'm going?

326
00:30:34,000 --> 00:30:36,000
Smart adversary will do that.

327
00:30:36,000 --> 00:30:47,000
Notice that most systems do not warn you when you log in successfully whether they have been in successful attempts before.

328
00:30:47,000 --> 00:30:51,000
Whether they should or not is an interesting question in and of itself.

329
00:30:51,000 --> 00:30:57,000
Because if they start telling you it will be meaningful only if you have good memory, if you log in regularly, you know what I mean?

330
00:30:57,000 --> 00:31:04,000
Like if you are one of those ill retentive people that logs it every day at 8 a.m. to your Wells Fargo account, yes, you will know.

331
00:31:04,000 --> 00:31:06,000
You say, what the hell?

332
00:31:06,000 --> 00:31:09,000
At 4 p.m. last night somebody entered the wrong password.

333
00:31:09,000 --> 00:31:10,000
Ah!

334
00:31:10,000 --> 00:31:15,000
But if you are like most people, you don't remember, you don't have that capacity.

335
00:31:15,000 --> 00:31:18,000
Most of us don't do this already.

336
00:31:18,000 --> 00:31:19,000
Everybody following this conversation?

337
00:31:19,000 --> 00:31:20,000
Yeah?

338
00:31:20,000 --> 00:31:21,000
Okay.

339
00:31:21,000 --> 00:31:25,000
So, anyway, back to this world.

340
00:31:25,000 --> 00:31:29,000
This is a nice balance between deployment and security, right?

341
00:31:29,000 --> 00:31:32,000
Because it's relatively easy to deploy.

342
00:31:32,000 --> 00:31:36,000
Minimally simple, blah, blah, blah.

343
00:31:36,000 --> 00:31:40,000
Now, two follow-up questions and we are done.

344
00:31:40,000 --> 00:31:41,000
That was two interesting things.

345
00:31:41,000 --> 00:31:43,000
Actually, what you raised is also interesting.

346
00:31:43,000 --> 00:31:45,000
I hadn't thought about that.

347
00:31:45,000 --> 00:31:51,000
Can we repurpose this theme to add a separate password?

348
00:31:51,000 --> 00:31:55,000
The Alice would have to remember two, two passwords.

349
00:31:55,000 --> 00:32:02,000
Well, one of them is real password and the other one is I'm being threatened, I'm under duress.

350
00:32:02,000 --> 00:32:12,000
Notice that banks use this system, you know, for PIN codes and combinations for like saves and stuff.

351
00:32:12,000 --> 00:32:14,000
There's two combinations.

352
00:32:14,000 --> 00:32:16,000
One is emergency, one is real.

353
00:32:16,000 --> 00:32:20,000
When you enter an emergency combination, the safe will open.

354
00:32:20,000 --> 00:32:24,000
But they will immediately notify the police or security.

355
00:32:24,000 --> 00:32:26,000
So the idea is the same here.

356
00:32:26,000 --> 00:32:31,000
If you have a list of, if you are Alice and you have a list of N passwords,

357
00:32:31,000 --> 00:32:37,000
it would be nice if you remembered two and only entered that other second one in case of emergency.

358
00:32:37,000 --> 00:32:41,000
Somebody puts a gun to your head and says, you know, log into your bank account and transfer money.

359
00:32:41,000 --> 00:32:46,000
Well, you enter, but the bank now knows that somebody is threatening you.

360
00:32:46,000 --> 00:32:48,000
Yeah, it'd be cool.

361
00:32:48,000 --> 00:32:52,000
And it can be done with the honey checker, right?

362
00:32:52,000 --> 00:32:59,000
The honey checker would raise an alarm when you enter that password that is signified in the emergency.

363
00:32:59,000 --> 00:33:02,000
And now, finally, there is a problem with the honey checker.

364
00:33:02,000 --> 00:33:06,000
Nothing is just beneficial.

365
00:33:06,000 --> 00:33:11,000
One of the things that the industry may aim to just recap it.

366
00:33:11,000 --> 00:33:13,000
Maybe the industry doesn't care to get into the computer system.

367
00:33:13,000 --> 00:33:16,000
He wants to inconvenience you as much as possible.

368
00:33:16,000 --> 00:33:23,000
So you imagine you are a large-ish organization where the system has numerous accounts, maybe thousands, right?

369
00:33:23,000 --> 00:33:29,000
This et cetera password file has like thousands or hundreds of accounts, employees, right?

370
00:33:29,000 --> 00:33:34,000
The adversary breaks one password.

371
00:33:34,000 --> 00:33:36,000
Just one.

372
00:33:36,000 --> 00:33:37,000
Okay?

373
00:33:37,000 --> 00:33:40,000
He wants to take his chances.

374
00:33:40,000 --> 00:33:42,000
He doesn't have to crack all of them, right?

375
00:33:42,000 --> 00:33:43,000
So the answer is easy.

376
00:33:43,000 --> 00:33:44,000
And enters that.

377
00:33:44,000 --> 00:33:45,000
Says, Alice, here's password.

378
00:33:45,000 --> 00:33:46,000
User name Alice, here's password.

379
00:33:46,000 --> 00:33:48,000
Immediately the alarm goes on.

380
00:33:48,000 --> 00:33:51,000
What happens at that point?

381
00:33:51,000 --> 00:33:56,000
At that point, everyone is locked out and everybody must change their password.

382
00:33:56,000 --> 00:33:59,000
That's a giant nightmare.

383
00:33:59,000 --> 00:34:04,000
So the adversary could be very happy just achieving that.

384
00:34:04,000 --> 00:34:09,000
If the adversary's goal is denial of service.

385
00:34:09,000 --> 00:34:11,000
Questions?

386
00:34:11,000 --> 00:34:16,000
No questions.

387
00:34:16,000 --> 00:34:17,000
All right.

388
00:34:17,000 --> 00:34:18,000
All right.

389
00:34:18,000 --> 00:34:21,000
Now it's time to switch to something different.

390
00:34:21,000 --> 00:34:26,000
Let me share the screen.

391
00:34:26,000 --> 00:34:27,000
All right.

392
00:34:27,000 --> 00:34:37,000
Now we're going to switch over to something called single synon or something called Kerberus.

393
00:34:37,000 --> 00:34:39,000
Anybody ever heard of Kerberus?

394
00:34:39,000 --> 00:34:42,000
Not from Greek mythology, but actual Kerberus.

395
00:34:42,000 --> 00:34:43,000
Yeah.

396
00:34:43,000 --> 00:34:44,000
Okay.

397
00:34:44,000 --> 00:34:46,000
Everybody ever heard of single synon?

398
00:34:46,000 --> 00:34:47,000
Okay.

399
00:34:47,000 --> 00:34:53,000
Well, some of you, many of you probably already used Kerberus without knowing it.

400
00:34:53,000 --> 00:34:56,000
Windows authentication, right?

401
00:34:56,000 --> 00:34:57,000
Distributed authentication on Windows.

402
00:34:57,000 --> 00:35:03,000
If you ever use ICS facilities for using, you know, Windows network, you've used Kerberus.

403
00:35:03,000 --> 00:35:05,000
It's underneath.

404
00:35:05,000 --> 00:35:08,000
And then we'll go on to web security.

405
00:35:08,000 --> 00:35:09,000
All right.

406
00:35:09,000 --> 00:35:12,000
So what is Kerberus or what is single synon?

407
00:35:12,000 --> 00:35:14,000
The idea of a single synon is very common.

408
00:35:14,000 --> 00:35:17,000
You have used it on the web, although not using Kerberus.

409
00:35:17,000 --> 00:35:21,000
Anybody know what OAuth is?

410
00:35:21,000 --> 00:35:22,000
Two people.

411
00:35:22,000 --> 00:35:23,000
Anybody else?

412
00:35:23,000 --> 00:35:24,000
Three.

413
00:35:24,000 --> 00:35:25,000
Okay.

414
00:35:25,000 --> 00:35:27,000
Anybody want to tell me what OAuth is?

415
00:35:27,000 --> 00:35:30,000
Based on, no wrong answers.

416
00:35:30,000 --> 00:35:32,000
What is OAuth?

417
00:35:32,000 --> 00:35:33,000
No?

418
00:35:33,000 --> 00:35:34,000
What does it do for you?

419
00:35:34,000 --> 00:35:35,000
Okay.

420
00:35:35,000 --> 00:35:36,000
Let me ask you.

421
00:35:36,000 --> 00:35:37,000
What does it do for you?

422
00:35:37,000 --> 00:35:38,000
You can access a different application.

423
00:35:38,000 --> 00:35:39,000
It's like an authentication.

424
00:35:39,000 --> 00:35:40,000
Right.

425
00:35:40,000 --> 00:35:41,000
So you log into Facebook.

426
00:35:41,000 --> 00:35:44,000
And you want to access, I don't know, TikTok or Instagram or something like that.

427
00:35:44,000 --> 00:35:45,000
Snapchat.

428
00:35:45,000 --> 00:35:46,000
And you do it without having to provide your username.

429
00:35:46,000 --> 00:35:47,000
How is that possible?

430
00:35:47,000 --> 00:35:48,000
Facebook instead?

431
00:35:48,000 --> 00:35:50,000
Well, it's not because everybody loves Facebook and respects Facebook.

432
00:35:50,000 --> 00:35:51,000
No.

433
00:35:51,000 --> 00:35:52,000
It's just Facebook authenticated you as somebody.

434
00:35:52,000 --> 00:36:01,000
And Facebook basically passes your credentials over to Instagram and says, this user has been

435
00:36:01,000 --> 00:36:02,000
authenticated.

436
00:36:02,000 --> 00:36:03,000
Google does the same thing, right?

437
00:36:03,000 --> 00:36:04,000
With Gmail.

438
00:36:04,000 --> 00:36:05,000
You're authenticated with using via Gmail and then you can use Google Drive.

439
00:36:05,000 --> 00:36:06,000
They had different applications.

440
00:36:06,000 --> 00:36:07,000
But you only signed on once.

441
00:36:07,000 --> 00:36:09,000
So the whole idea is to make it easy for users like you and you.

442
00:36:09,000 --> 00:36:12,000
You can make it easy for users like Google Drive to get your credentials.

443
00:36:12,000 --> 00:36:13,000
It's not because everybody loves Facebook and respects Facebook.

444
00:36:13,000 --> 00:36:14,000
No.

445
00:36:14,000 --> 00:36:15,000
It's just Facebook authenticated you as somebody and Facebook basically passes your credentials

446
00:36:15,000 --> 00:36:17,000
over to Instagram and says, this user has been authenticated.

447
00:36:17,000 --> 00:36:18,000
Google does the same thing, right?

448
00:36:18,000 --> 00:36:19,000
With Gmail.

449
00:36:19,000 --> 00:36:20,000
You authenticated with using via Gmail and then you can use Google Drive.

450
00:36:20,000 --> 00:36:22,000
They have different applications but you only signed on once.

451
00:36:22,000 --> 00:36:33,000
So the whole idea is to make it easy for users like you and Google Drive to use Chrome.

452
00:36:33,000 --> 00:36:40,760
users like you and me, first to remember fewer passwords, and second having to authenticate

453
00:36:40,760 --> 00:36:47,080
many many times. You know what it means to authenticate many times. Not just because

454
00:36:47,080 --> 00:36:51,080
let's say IMT requires us to re-authenticate, but I'm talking about authenticate many times

455
00:36:51,080 --> 00:37:00,040
to different applications. So that's the whole idea behind single sign-on, is that you sign

456
00:37:00,040 --> 00:37:08,040
on, you log in. Sign on is just another word for login. You log in once, and you don't do it for every application.

457
00:37:09,400 --> 00:37:15,720
So the basic problem that Kerberos in general, single sign-on tries to solve is this. You have

458
00:37:16,360 --> 00:37:25,640
many users and you have many what's called servers. If it helps you think of servers as being even like

459
00:37:25,640 --> 00:37:35,640
apps or applications that run on different places. Originally and even today, the Kerberos is mostly

460
00:37:35,640 --> 00:37:43,240
used within organizations. So suppose you're working in an organization like UCI or a commercials entity

461
00:37:43,240 --> 00:37:51,480
of some sort of company. Not a tiny starter, but a company of certain size. And so you have a bunch of

462
00:37:51,480 --> 00:37:59,080
users with different job titles and different privileges. Some users can access some resources,

463
00:37:59,080 --> 00:38:05,880
some and not others, and no different users depending on their job, may have unique access

464
00:38:05,880 --> 00:38:11,560
policies governing their access to resources. There are compute servers, there are GPUs, there are storage

465
00:38:11,560 --> 00:38:18,440
devices, there are printers, there are 3D printers. There are all kinds of equipment and there are all kinds of

466
00:38:18,440 --> 00:38:25,160
services that those that equipment gives you, right? So we call those things servers in this lecture.

467
00:38:26,680 --> 00:38:34,440
So the main problem is how a user proves their identity, right? Through a multitude of servers,

468
00:38:34,440 --> 00:38:41,160
right? Because a given user will come in the morning to work, will log in, and then during the day,

469
00:38:41,160 --> 00:38:46,360
in the course of a typical day, will want to access some service. I want to print a document,

470
00:38:46,360 --> 00:38:56,760
access company calendar, I don't know, run a job on an expensive GPU rack somewhere, okay? These kind of services.

471
00:38:58,360 --> 00:39:06,920
So, clearly a naive solution is to say, well, every service or every server that offers a service

472
00:39:06,920 --> 00:39:11,960
should have its own account database, should have its own account database, and every user that is

473
00:39:11,960 --> 00:39:20,760
allowed to access that server should have an account, okay? That could make sense. So if you want to,

474
00:39:20,760 --> 00:39:27,160
if you're allowed to use the GPU farm, well, have an account there. If you're allowed to use that printer,

475
00:39:27,160 --> 00:39:33,160
well, there's going to be a printer server that will maintain that account database. Same for storage devices and anything else.

476
00:39:33,160 --> 00:39:47,000
That would work, but it wouldn't scale. Because that means that we have, coming back to the problem

477
00:39:47,000 --> 00:39:52,040
with the password issue we discussed in the last couple of lectures, you would have to, as a user,

478
00:39:52,040 --> 00:40:01,160
as an employee, you would have to remember as many passwords, as many user names, but at least as many

479
00:40:01,160 --> 00:40:07,240
passwords, maybe the username is the same, as many passwords as there are servers, and you will

480
00:40:07,240 --> 00:40:14,920
physically have as many accounts as there are servers. And of course, if you have all these servers,

481
00:40:14,920 --> 00:40:22,040
each running its own account database or accounting system, well, an adversary who breaks into any of

482
00:40:22,040 --> 00:40:27,160
them already gets something. Potentially, if you reuse passwords, you will get your passwords on other

483
00:40:27,160 --> 00:40:33,720
servers. And we know the people who use passwords, right? So it's not a scalable world if you have

484
00:40:34,520 --> 00:40:40,520
every server maintaining its own database of users and doing its own access control.

485
00:40:44,440 --> 00:40:45,000
All right, so

486
00:40:47,720 --> 00:40:55,880
even if you do, in fact, have the same password for every server, right, separately, if you want to change it,

487
00:40:55,880 --> 00:41:00,600
you would have to contact each one individually, which is tremendous damage.

488
00:41:03,400 --> 00:41:09,000
So, clearly, we want to do something better. We want to have better security,

489
00:41:09,000 --> 00:41:14,920
means be secure against eavesdroppers and actively malicious adversaries. Remember,

490
00:41:14,920 --> 00:41:20,760
eavesdroppers just listen, malicious adversaries, actively active adversaries interfere, right?

491
00:41:20,760 --> 00:41:26,120
They introduce their own traffic, they delete traffic, they retard traffic, they change traffic,

492
00:41:26,120 --> 00:41:33,000
right? When I say traffic, I mean packets, communication. Also, adversaries can keep that in

493
00:41:33,000 --> 00:41:38,120
mind, and always in this course. Adversaries could very well be legitimate users who are inside.

494
00:41:39,480 --> 00:41:47,320
A lot of spectacular breaches in this world occur, not because of the evil hackers in a third world

495
00:41:47,320 --> 00:41:54,760
country or some other faraway place, they occur because there's a rotten insider in their organization.

496
00:41:55,880 --> 00:42:01,480
Of course, there must be reliability, so that whatever service you do, it must be always available.

497
00:42:01,480 --> 00:42:08,280
Users should not have to enter passwords and authenticate multiple times. The whole point is

498
00:42:08,280 --> 00:42:13,000
log in once and get access to as many servers and services as you can.

499
00:42:13,000 --> 00:42:21,880
So, if a user is asked to enter a password, doing so like once a day is considered okay. Maybe twice a day,

500
00:42:21,880 --> 00:42:27,560
but not every time you want to do something. That's super annoying. We all know this, right?

501
00:42:29,080 --> 00:42:36,280
It's annoying what we have here at UCI. And of course, it must be scalable, right? Because we want it

502
00:42:36,280 --> 00:42:41,000
to scale to large number of users and maybe smaller, but still a large number of servers.

503
00:42:44,120 --> 00:42:50,920
We want to deal with impersonation or when Alice is a legitimate user and Bob decides to log in as Alice,

504
00:42:50,920 --> 00:42:57,160
or some outside adversary just tries to log in. We cannot trust the location. For example,

505
00:42:57,160 --> 00:43:01,160
if you work in a company where computing, and many companies do this, right? They don't allow you to

506
00:43:01,160 --> 00:43:10,280
bring personal devices like laptops, right? You come to work, you either take your work-issued laptop

507
00:43:10,280 --> 00:43:16,360
and plug it in to the docking station, or you don't do even that. You just come to work and you log into

508
00:43:16,360 --> 00:43:24,520
the workstation on your desktop, whatever that is assigned to you. So, trivial idea would be to just say,

509
00:43:24,520 --> 00:43:30,600
well, you know, a person gained access to this desktop and this desktop is inside the secure premises,

510
00:43:30,600 --> 00:43:36,680
therefore, it's enough to just use an IP-based authentication, IP address-based authentication.

511
00:43:36,680 --> 00:43:42,200
That's not good. That's not good enough because IP addresses and even MAC addresses can be changed.

512
00:43:43,080 --> 00:43:44,920
Okay, so they're a poor form of authentication.

513
00:43:44,920 --> 00:43:57,000
Let's see. You have to be resilient to eavesdropping. You have to be resilient to replay, right?

514
00:43:57,000 --> 00:44:03,480
Replay is just basically replaying previously sent information, right? If you trap somebody's password

515
00:44:03,480 --> 00:44:08,680
in a clear text or somebody's packet that is actually, forget clear. If you trap a packet that has

516
00:44:08,680 --> 00:44:14,840
Alice's password in an encrypted form and you know that that packet carries Alice's password

517
00:44:14,840 --> 00:44:20,920
in an encrypted form, you can replay it at a later time and gain access to Alice's account,

518
00:44:21,640 --> 00:44:27,480
unless the password carries it in some other information like, for example, timestamp or something

519
00:44:27,480 --> 00:44:37,160
else. Okay, so you get the idea, I think, of what we want to do. So in Kerberos, the main component is

520
00:44:37,160 --> 00:44:44,520
something called the trusted third party. Trusted third party, or TTP, is the general concept.

521
00:44:45,160 --> 00:44:50,040
Okay, and by the way, Kerberos is called Kerberos because it's a three-headed dog from Greek mythology.

522
00:44:50,760 --> 00:44:56,440
There's some story behind it that I don't quite remember. Anyway, the idea is this. That

523
00:44:57,320 --> 00:45:06,840
pink box with the three dogs, that's the Kerberos trusted third party. Think of it as like the system.

524
00:45:07,720 --> 00:45:18,200
It is trusted. It maintains a relationship with every user and with every server. Okay,

525
00:45:18,200 --> 00:45:25,880
it's like the security brains of their, of the organization. So it knows all passwords. Oh,

526
00:45:25,880 --> 00:45:34,840
knows, I mean, knows as much as like a UX, that's the password. Actually, no, it knows all

527
00:45:34,840 --> 00:45:40,520
passwords for all users and it also performs what's called access control. So when a user comes in and

528
00:45:40,520 --> 00:45:47,480
comes in and authenticates and later the user says, oh, my name is Alice. I have authenticated.

529
00:45:47,480 --> 00:45:54,600
I want to access the GPU farm to run this job. The server, this trusted third party will say,

530
00:45:55,400 --> 00:46:01,800
are you allowed to do so? And that's called access control, right? This is separate from everything

531
00:46:01,800 --> 00:46:06,680
we discussed so far, right? Access control means do you have the right to access the GPU farm?

532
00:46:07,720 --> 00:46:14,360
Maybe Alice is not because Alice worked in the janitorial department. But Bob, who works in a,

533
00:46:14,360 --> 00:46:25,640
I don't know, coding department is allowed to ask. But maybe Alice is allowed to, you know, access some

534
00:46:25,640 --> 00:46:32,600
financial system and Bob is not. Okay? So you get the idea. Access control is very important and they,

535
00:46:32,600 --> 00:46:37,000
one of the roles of the trusted third party is to perform access control.

536
00:46:37,000 --> 00:46:46,280
It is a convenient entity because there's only one. You authenticate only to it directly as a user.

537
00:46:47,560 --> 00:46:53,080
And you do not authenticate directly to anybody else but the trusted third party.

538
00:46:55,960 --> 00:47:00,360
It is also, I admit from the start, anytime you have a system like this,

539
00:47:00,360 --> 00:47:06,760
it's going to be a single point of failure. So that is true about all systems that use trusted third party.

540
00:47:07,000 --> 00:47:14,360
Unless there's a hot backup somewhere. Okay? If the system fails, nobody can log in. Nobody can access it.

541
00:47:16,360 --> 00:47:21,560
Okay? That's from, that's, that's a problem. That's part and parcel of the curbers.

542
00:47:22,200 --> 00:47:27,560
And clearly that requires physical security, kind of like I mentioned earlier with the certification

543
00:47:27,560 --> 00:47:33,240
authorities, right? Require special security accommodations while so does the curbers trusted third party.

544
00:47:33,240 --> 00:47:46,680
So here's a, a bird's eye view. A user, let's say, comes in the morning and enters username, password.

545
00:47:46,680 --> 00:47:55,880
So that's the user experience. What's it? Well, assume, right? So basically proves identity and says,

546
00:47:55,880 --> 00:48:01,720
okay, now I want to access some server, like a print server. Okay.

547
00:48:01,720 --> 00:48:10,520
Okay. User then, if he's authorized, only if authorized, will receive a, what's called a ticket.

548
00:48:11,640 --> 00:48:16,840
And a ticket, like a ticket in the middleware, allows him to go to the print server and say,

549
00:48:16,840 --> 00:48:30,200
see, see, I got a ticket, I can print on you. Right? So that's essentially a high level,

550
00:48:30,200 --> 00:48:36,920
the interaction in curbers. And that's pretty much how most single sign-on services work in the real world.

551
00:48:36,920 --> 00:48:43,480
So you authenticate as a user once, and from that point on, everything else takes place under the curbers,

552
00:48:43,480 --> 00:48:45,400
being transparent to you, the human.

553
00:48:49,080 --> 00:48:56,840
So what is that mysterious ticket? Well, a ticket should be, as you can already guess,

554
00:48:56,840 --> 00:49:03,800
something secure, something cryptographically protected. Right? Because if it's not cryptographically

555
00:49:03,800 --> 00:49:09,320
protected, it can be hijacked, it can be modified, reused, abused, et cetera. So there's going to be

556
00:49:09,320 --> 00:49:15,080
some cryptographic protection for sure. It cannot include a server's password, obviously. Remember,

557
00:49:15,080 --> 00:49:21,800
the server, I did forget to mention this. So in curbers, every user shares a password,

558
00:49:21,800 --> 00:49:28,920
or a long-term key with a trusted third party. But also each server shares a long-term key with a trusted

559
00:49:28,920 --> 00:49:35,960
third party. Okay? So as far as the trusted third party is concerned, it has a database of all the

560
00:49:35,960 --> 00:49:42,440
users and all the servers. And for each user and for each server, it has a long-term key. Okay?

561
00:49:42,440 --> 00:49:48,120
Except for servers are not humans, so that key does not need to be a password. It can be a random,

562
00:49:48,120 --> 00:50:02,040
strong, long key. And it shouldn't change very often. So the ticket must have some information

563
00:50:03,800 --> 00:50:10,920
that only the server can read and understand that tells the server that this user is authorized to use

564
00:50:10,920 --> 00:50:19,800
this service right now. And for how long? So remember, it's important to tell the server, like the print

565
00:50:19,800 --> 00:50:27,720
server, that this ticket is for you. This is for the print server. And it refers to the already

566
00:50:27,720 --> 00:50:35,880
authenticated user, Alice. So this is for Alice to print on you now. Because if you don't say when,

567
00:50:36,840 --> 00:50:42,600
then the ticket can be used by others, right? Or it can be used by Alice in perpetuity.

568
00:50:45,160 --> 00:50:51,640
But remember, in the real world, Alice may be a good employee today and a fired employee tomorrow.

569
00:50:52,920 --> 00:50:58,600
Yes? So that's why tickets are only issued for a certain period of time.

570
00:50:58,600 --> 00:51:07,880
8 hours, 10 hours, 24 hours. Kind of like our authenticators here would do, right? When you

571
00:51:07,880 --> 00:51:13,160
use, when you log into UCI services, right? Eventually, your ticket will expire. And you'll get

572
00:51:13,160 --> 00:51:23,080
a new window to re-authenticate. The same idea. Okay, so the ticket is something, in this case,

573
00:51:23,080 --> 00:51:29,000
encrypted for the server with a key known only to the server and the DTP. But the user has no idea

574
00:51:29,000 --> 00:51:33,640
about that key. Server can then decrypt the ticket and verify the information and says,

575
00:51:33,640 --> 00:51:39,000
oh yeah, this is for me, because I can decrypt it, so it must be for me. And it refers to Alice. Well,

576
00:51:39,000 --> 00:51:46,040
Alice is that user. And of course, lack of print. And do whatever.

577
00:51:46,040 --> 00:51:52,520
All right. All right. So that's essentially how it goes.

578
00:51:59,480 --> 00:52:06,680
Inside the ticket, you would want to find the username, meaning this is the server to whom it's

579
00:52:06,680 --> 00:52:13,720
issued. The name of the server is who am I, the server, brain server, right? Who is the user?

580
00:52:13,720 --> 00:52:19,720
Alice. Address of the user workstation. That's important so that the ticket is not movable from

581
00:52:19,720 --> 00:52:25,160
one place to another. The ticket is valid for this device. You know how, with a single sign-on,

582
00:52:25,960 --> 00:52:31,560
with an OID, if you change devices, you'll have to re-authenticate. You move from one laptop to

583
00:52:31,560 --> 00:52:36,280
another, or desktop to laptop, or smartphone, whatever, you re-authenticate. Same here. There's

584
00:52:36,280 --> 00:52:43,880
an IP address. Even though IP or address is not a reliable form of authentication, the ticket is

585
00:52:43,880 --> 00:52:54,600
tied to the IP address. Yeah? Important. Lifetime. Valid from, valid to, or until. Why is that? Because

586
00:52:54,600 --> 00:52:59,240
we want to know when the ticket is valid. Sometimes it's not valid yet. Sometimes tickets are issued into

587
00:52:59,240 --> 00:53:05,000
the future. And this ticket will be valid at 8am. Because now 7am, you can still get a ticket, but

588
00:53:05,000 --> 00:53:11,880
you can't print till 8am. And until, right? And a few other things. At least, it needs to include

589
00:53:11,880 --> 00:53:19,080
something else called a session key. A session key is a short-term key generated by the trusted third party

590
00:53:19,080 --> 00:53:25,960
server. For Alice and the server, for user and the server to communicate with. To protect their

591
00:53:25,960 --> 00:53:32,040
communication. Does that make sense? Stop me if you lost me already.

592
00:53:37,480 --> 00:53:48,600
So, now let's zoom in. How is an actual session with Kerberos going? Alice comes in the morning.

593
00:53:49,240 --> 00:53:57,240
Alice wants to log in. She says, my name is Alice, user ID Alice, password, so and so on. The real

594
00:53:57,240 --> 00:54:05,480
password is not really sentiment clear, okay? But the idea is that somehow it's something that allows

595
00:54:06,520 --> 00:54:13,080
the trusted third party. Here it's called authentication server, and you'll see why. And when it

596
00:54:13,080 --> 00:54:18,040
authenticates Alice, it will send back an encrypted ticket.

597
00:54:22,920 --> 00:54:28,040
The problem with this approach is that the password would be in a clear text, or even a function of the

598
00:54:28,040 --> 00:54:33,720
password would be in the clear text. And so an eavesdropper could essentially impersonate the user.

599
00:54:33,720 --> 00:54:39,800
So you cannot send just encrypted password or clear text password, because that would be one.

600
00:54:42,520 --> 00:54:47,640
And it would require you to do this for every service, right? So for every server which is not good.

601
00:54:48,680 --> 00:54:55,720
So Kerberos adopts the following system. So here you see this dotted pink

602
00:54:55,720 --> 00:55:04,440
contour around two entities. And then the reason that it's there is to say that there are two,

603
00:55:04,440 --> 00:55:10,200
like you can think about two programs and two functions, but they're inside the same platform.

604
00:55:10,200 --> 00:55:16,360
That means there's one device that runs both of them. One is called the key distribution center,

605
00:55:16,360 --> 00:55:19,000
and one is called ticket granting service, but they're one in the same.

606
00:55:19,000 --> 00:55:24,360
They're like two processes running in the same machine. And they are the TTP.

607
00:55:26,680 --> 00:55:27,720
So the user

608
00:55:33,320 --> 00:55:41,880
will come after having authenticated initially, right, and pooling his identity once, will go back and say,

609
00:55:41,880 --> 00:55:48,760
hey, I want to access the PGS service. Okay, my name is Joe, in this case.

610
00:55:51,480 --> 00:55:57,560
And the system will say, okay, you say your name is Joe. Notice no password. Notice no password there.

611
00:55:57,560 --> 00:56:03,400
First message is no password. Just says, my name is Joe. I want to access the service called PGS,

612
00:56:03,400 --> 00:56:04,600
Ticket Granting Service.

613
00:56:04,600 --> 00:56:13,160
The trusted third party replies with an encrypted ticket granting service ticket,

614
00:56:15,720 --> 00:56:21,800
where the ticket itself is encrypted under a key, you see it's green, derived from the user's password.

615
00:56:24,280 --> 00:56:31,080
So that trusted third party knows the user's password and knows how to derive a key,

616
00:56:31,080 --> 00:56:36,360
because we don't use password, because encryption is directly, right, when we hash them and derive them.

617
00:56:37,320 --> 00:56:45,240
So that green contour means that the DGS ticket is encrypted with a key derived from the user's password.

618
00:56:47,400 --> 00:56:53,240
Okay, now the user, if he knows the password, assuming that user knows the password, can decrypt the ticket.

619
00:56:54,040 --> 00:56:58,840
And then come to the ticket granting service and say, hey, here is my ticket

620
00:56:58,840 --> 00:57:09,080
that I was issued previously. Can you gain, can you give me access to a server, like printer, file,

621
00:57:09,080 --> 00:57:14,920
server, storage device, whatever, view farm, and specify. And then get back and return,

622
00:57:14,920 --> 00:57:18,920
if he's allowed to access that server, get back an encrypted service ticket.

623
00:57:18,920 --> 00:57:27,400
Now, these two first lines, they happen, right, one after another. This and this happen one after another.

624
00:57:28,200 --> 00:57:32,200
These two are not necessarily close, meaning this can happen an hour after.

625
00:57:33,400 --> 00:57:40,120
Meaning that the user logs in, but the user doesn't use any service for a while, like doesn't need to print, right, doesn't need to do anything.

626
00:57:40,120 --> 00:57:48,760
Maybe the user walks away or starts reading a book in the box station, right. But when the user actually wants to do something, then this happens.

627
00:57:54,520 --> 00:57:54,920
And so,

628
00:57:58,280 --> 00:58:03,080
stay away from me for a second. He gets the encrypted service ticket which he can decrypt.

629
00:58:03,080 --> 00:58:11,000
Well, actually part of it, you'll see. This part he cannot because he doesn't know the yellow key.

630
00:58:11,560 --> 00:58:18,120
The yellow key is the key of that service. And so he forwards it to the service and says, hey,

631
00:58:19,080 --> 00:58:21,720
my name is Joe, I have a ticket to use you.

632
00:58:25,720 --> 00:58:29,000
And that guy decrypts it, verifies it, and allows it.

633
00:58:33,080 --> 00:58:36,600
The problem with this is that it's still not good enough because the ticket can be hijacked.

634
00:58:36,600 --> 00:58:38,040
Because you see the ticket is sent,

635
00:58:39,560 --> 00:58:46,600
kind of encrypted, right, and essentially anybody can intercept the ticket and hijack.

636
00:58:52,040 --> 00:58:53,960
And the server,

637
00:58:56,760 --> 00:59:02,600
so the printer, whatever, the file server, it needs to make sure that the user presenting the ticket

638
00:59:02,600 --> 00:59:06,280
is the same to whom the ticket was originally issued by the DTP.

639
00:59:09,000 --> 00:59:09,320
Okay.

640
00:59:11,080 --> 00:59:16,920
Conversely, the server needs to authenticate to the user. So if the user thinks he got access to a printer

641
00:59:16,920 --> 00:59:22,600
in the next room, okay, the user wants to make sure that he's talking to the printer in the next room

642
00:59:22,600 --> 00:59:28,440
and not a printer across campus. Okay. So that's what's called mutual authentication.

643
00:59:29,000 --> 00:59:32,760
The server needs to authenticate the user. The user needs to authenticate the server.

644
00:59:35,240 --> 00:59:39,880
So now we are ready to look at the actual Kerberos. So in Kerberos here is the notation.

645
00:59:41,880 --> 00:59:48,600
KC is the long-term key of a client C. The Kerberos uses the terminology client. The client is user.

646
00:59:48,600 --> 00:59:55,160
Okay. It's derived from the user's password, known to the KDC, and the client.

647
00:59:55,160 --> 01:00:01,160
TGS is the long-term key of the TGS. TGS, remember, is that part of the trusted enterprise, right,

648
01:00:01,160 --> 01:00:09,000
and sits there all for that. Only it knows it, nobody else knows it. So this is not a shared key.

649
01:00:09,000 --> 01:00:14,680
It's not a private key as in public private key, but it's a key only the TGS knows. So that's a

650
01:00:14,680 --> 01:00:24,280
little weird. Key V is the long-term key of a server V, okay, like a printer server. V and TGS know it,

651
01:00:24,280 --> 01:00:32,520
but nobody else does. Then this notation refers to a key that is short-term shared between the client,

652
01:00:32,520 --> 01:00:42,280
Alice, Joe, and TGS. And KCV is the shorter term. This is called the session key, okay? That is,

653
01:00:42,280 --> 01:00:49,080
will be shared between the user, client, and the server. You might get a little bleary at it at this

654
01:00:49,080 --> 01:00:56,200
point. It won't become clear. So here's the actual single sign on the Kerberos.

655
01:00:56,200 --> 01:01:07,720
So let's just finish on this slide. So the user has it on their device, whatever, a smartphone,

656
01:01:07,720 --> 01:01:13,640
workstation, desktop, et cetera. He enters the password and there's a program that is client

657
01:01:13,640 --> 01:01:20,520
programming. A purposeful key in it. You have to install it. And what it does is that program

658
01:01:20,520 --> 01:01:28,680
actually communicates the KDC. So it converts the password into this long-term key, right,

659
01:01:28,680 --> 01:01:38,680
that presumably is shared with the KDC. It then sends a clear text packet to the KDC or DTP. It

660
01:01:38,680 --> 01:01:45,160
says the ID of the client, that's username, the ID of the TGS, that's reserved, that's kind of fixed,

661
01:01:45,160 --> 01:01:52,840
the name of the TGS, and the current time, okay? Notice this packet is not protected. There's no

662
01:01:52,840 --> 01:02:02,760
authentication. There's no encryption. If the user exists, right, right, because if they specify

663
01:02:02,760 --> 01:02:08,280
ID that does not exist, they get no answer. But if the user exists and is in good standing,

664
01:02:08,280 --> 01:02:15,160
meaning not revoked, not expunged, the KDC will reply to this green stuff, which is the encryption

665
01:02:15,160 --> 01:02:23,160
under the client, under the user's long-term key of a short-term PTC, the blue key, that is to be used

666
01:02:23,160 --> 01:02:29,240
from now on to talk to the DGS. The ID of the DGS should match the one in the blue, the issue should

667
01:02:29,240 --> 01:02:36,760
match. The time, the KDC means that the time, the current time on that side of the KDC. Lifetime,

668
01:02:37,480 --> 01:02:43,560
how long the ticket is valid, right? It's two from two. And a red thing, which by the way,

669
01:02:43,560 --> 01:02:47,960
looks very small, but it's very important. It's a ticket for the DGS. So actually that red thing is

670
01:02:47,960 --> 01:02:56,280
actually big, okay? It is an encrypted ticket that only DGS can read. So this green block comes to the

671
01:02:56,280 --> 01:03:02,360
user, the user because assuming, assuming the user knows the right KDC, and this is not an impersonator,

672
01:03:02,360 --> 01:03:09,160
right?

673
01:03:09,160 --> 01:03:16,360
The crypt, the green part, learns KC DGS and ticket DGS, the orange one.

674
01:03:16,360 --> 01:03:23,800
Okay? He also verifies that the time, for example, the time C and the time KDC have to be near. If

675
01:03:23,800 --> 01:03:29,080
something is wrong there, you know, that's a, there's a problem with time synchronization,

676
01:03:29,080 --> 01:03:35,880
right? If the ID DGS does not match, for example, right? You see, the user wants to go to one DGS,

677
01:03:35,880 --> 01:03:41,800
the different DGS, again, it's a problem. It's an error. Otherwise, he obtains the

678
01:03:41,800 --> 01:03:52,280
orange ticket DGS and that key, KC DGS. Okay? So that's the initial single sign-on. That is the

679
01:03:52,280 --> 01:04:02,600
only time the user enters a password. That's it. Now, here's where I obtain a service ticket.

680
01:04:03,000 --> 01:04:08,440
But since it's 1217, I think, let's just stop here.

681
01:04:12,120 --> 01:04:16,200
Yeah, you all look a little confused by your own, by your own notation.

682
01:04:17,560 --> 01:04:23,400
Trust me, if you stare at the slides for a little bit, it will all become clear.

683
01:04:23,400 --> 01:04:36,840
You are right here.

684
01:04:36,840 --> 01:04:37,800
Okay.

685
01:04:41,800 --> 01:04:42,280
Okay.

686
01:04:42,280 --> 01:04:53,720
Yeah.

